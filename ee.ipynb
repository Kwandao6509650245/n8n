{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6df7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.21' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "from langchain_community.vectorstores import PGVector\n",
    "from langchain_core.documents import Document\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. กำหนดค่า Ollama ---\n",
    "# ใช้ OllamaLLM เมื่อคุณต้องการแค่ดึงข้อความ ไม่ได้ใช้คุณสมบัติ Chat Model เต็มรูปแบบ\n",
    "model = OllamaLLM(model=\"llama3.2\", base_url=\"http://localhost:11434\")\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "# --- 2. กำหนดค่าการเชื่อมต่อ PostgreSQL ---\n",
    "DB_USER = \"myuser\"\n",
    "DB_PASSWORD = \"mypassword\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"mydatabase\"\n",
    "CONNECTION_STRING = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "COLLECTION_NAME = \"my_ollama_documents_collection\"\n",
    "\n",
    "# # --- 3. ดึงข้อมูลจากไฟล์ CSV และเตรียม LangChain Documents ---\n",
    "# csv_file_path = \"my_doc.csv\" # ตรวจสอบพาธของไฟล์ CSV ของคุณ\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_file_path}\")\n",
    "    exit()\n",
    "\n",
    "docs = []\n",
    "# กำหนดชื่อคอลัมน์ที่เป็นเนื้อหาหลักที่คุณต้องการให้ AI ใช้ค้นหา\n",
    "# *** ต้องตรงกับชื่อคอลัมน์ในไฟล์ CSV ของคุณเป๊ะๆ ***\n",
    "content_column = 'คำถาม' \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # ตรวจสอบว่าคอลัมน์เนื้อหาหลักไม่ว่าง\n",
    "    if pd.isna(row[content_column]):\n",
    "        continue # ข้ามแถวที่ไม่มีเนื้อหาหลัก\n",
    "\n",
    "    page_content = str(row[content_column])\n",
    "    \n",
    "    # สร้าง metadata จากคอลัมน์อื่นๆ ทั้งหมด ยกเว้นคอลัมน์เนื้อหาหลัก\n",
    "    # ในกรณีนี้ 'คำตอบ' จะถูกเก็บใน metadata ของเอกสาร\n",
    "    metadata = row.drop(content_column).to_dict() \n",
    "\n",
    "    docs.append(Document(page_content=page_content, metadata=metadata))\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents from CSV.\")\n",
    "\n",
    "# # --- 4. สร้าง Vector Store และบันทึกข้อมูลลง PostgreSQL ---\n",
    "# print(\"Connecting to PGVector store and adding documents...\")\n",
    "# # 'pre_delete_collection=True' จะลบ collection เก่าก่อนเพิ่มใหม่เสมอ\n",
    "vectorstore = PGVector.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=True # ตั้งค่าเป็น True ถ้าต้องการลบข้อมูลเก่าใน collection ก่อนเพิ่มใหม่\n",
    ")\n",
    "print(f\"Documents added to PostgreSQL in collection '{COLLECTION_NAME}'.\")\n",
    "\n",
    "# --- 5. ใช้ Vector Store เป็น Retriever และค้นหา ---\n",
    "# คุณสามารถปรับ k เพื่อดึงจำนวนเอกสารที่ต้องการมาตรวจสอบได้\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1}) \n",
    "\n",
    "# ทำการค้นหาข้อความที่คล้ายคลึงที่สุด\n",
    "query_text = \"ขอเปลี่ยนรหัสผ่าน\" # คำถามที่คุณต้องการใช้ค้นหา\n",
    "retrieved_documents = retriever.invoke(query_text)\n",
    "\n",
    "print(f\"\\n--- Retrieved Documents for query: '{query_text}' ---\")\n",
    "if retrieved_documents:\n",
    "    # แสดงเนื้อหาของเอกสารที่ถูกดึงมา (ซึ่งตอนนี้คือ 'ประโยคขอแก้ไขข้อมูลอีเมล')\n",
    "    print(f\"Content (จากคอลัมน์ 'คำถาม'): {retrieved_documents[0].page_content}\")\n",
    "    \n",
    "    # แสดง metadata ซึ่งจะรวมถึงคอลัมน์ 'คำตอบ' ที่เราต้องการดู\n",
    "    print(f\"Metadata (รวมถึง 'คำตอบ'): {retrieved_documents[0].metadata}\")\n",
    "    \n",
    "    # แสดง 'คำตอบ' ที่ตรงกันจาก metadata โดยตรง\n",
    "    if 'คำตอบ' in retrieved_documents[0].metadata:\n",
    "        print(f\"**คำตอบที่เกี่ยวข้อง:** {retrieved_documents[0].metadata['คำตอบ']}\")\n",
    "    else:\n",
    "        print(\"ไม่พบคอลัมน์ 'คำตอบ' ใน metadata ของเอกสารที่ดึงมา\")\n",
    "else:\n",
    "    print(\"ไม่พบเอกสารสำหรับคำถามนี้\")\n",
    "\n",
    "print(\"\\nProcess completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edb860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 documents from CSV.\n",
      "Connecting to PGVector store and adding documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stamp7ven\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\vectorstores\\pgvector.py:490: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  store = cls(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents added to PostgreSQL in collection 'my_ollama_documents_collection'.\n",
      "\n",
      "--- Generating Answer for query: 'วิธีเปลี่ยนรหัสผ่าน' ---\n",
      "ขอโทษครับ/ค่ะ ผมไม่สามารถช่วยคุณเปลี่ยนรหัสผ่านได้ครับ/ค่ะ เนื่องจากการเปลี่ยนรหัสผ่านเป็นกระบวนการที่ต้องทำโดยผู้ใช้ตัวเอง และผมไม่มีข้อมูลที่ถูกต้องเกี่ยวกับการเปลี่ยนรหัสผ่านทางออนไลน์หรือไม่ครับ/ค่ะ\n",
      "\n",
      "หากคุณต้องการเปลี่ยนรหัสผ่าน คุณสามารถอ้างอิงจากคำตอบที่ให้ไว้ในข้อมูลบริบท (context) ที่มีครับ/ค่ะ โดยทำตามขั้นตอนดังนี้:\n",
      "1. เข้าสู่ระบบ ด้วยบัญชีผู้ใช้งานปัจจุบัน\n",
      "2. ไปที่เมนู บัญชี > เปลี่ยนรหัสผ่าน\n",
      "3. กรอกข้อมูลดังนี้\n",
      "4. รหัสผ่านเดิม\n",
      "5. รหัสผ่านใหม่\n",
      "6. ยืนยันรหัสผ่านใหม่\n",
      "7. กดปุ่ม บันทึก เพื่อยืนยันการเปลี่ยนรหัสผ่าน\n",
      "8. ระบบจะแจ้งว่าเปลี่ยนรหัสผ่านสำเร็จครับ/ค่ะ\n",
      "\n",
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings, ChatOllama # เพิ่ม ChatOllama\n",
    "from langchain_community.vectorstores import PGVector\n",
    "from langchain_core.documents import Document\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate # เพิ่ม\n",
    "from langchain_core.output_parsers import StrOutputParser # เพิ่ม\n",
    "from langchain_core.runnables import RunnablePassthrough # เพิ่ม\n",
    "\n",
    "# --- 1. กำหนดค่า Ollama ---\n",
    "# เปลี่ยนเป็น ChatOllama เพื่อให้รองรับ ChatPromptTemplate และการสร้างคำตอบแบบสนทนา\n",
    "model = ChatOllama(model=\"llama3.2\", base_url=\"http://localhost:11434\")\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "# --- 2. กำหนดค่าการเชื่อมต่อ PostgreSQL ---\n",
    "DB_USER = \"myuser\"\n",
    "DB_PASSWORD = \"mypassword\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"mydatabase\"\n",
    "CONNECTION_STRING = f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "COLLECTION_NAME = \"my_ollama_documents_collection\"\n",
    "\n",
    "# --- 3. ดึงข้อมูลจากไฟล์ CSV และเตรียม LangChain Documents ---\n",
    "csv_file_path = \"my_doc.csv\" # ตรวจสอบพาธของไฟล์ CSV ของคุณ\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path, encoding='utf-8')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_file_path}\")\n",
    "    exit()\n",
    "\n",
    "docs = []\n",
    "# กำหนดชื่อคอลัมน์ที่เป็นเนื้อหาหลักที่คุณต้องการให้ AI ใช้ค้นหา\n",
    "# *** ต้องตรงกับชื่อคอลัมน์ในไฟล์ CSV ของคุณเป๊ะๆ ***\n",
    "content_column = 'คำถาม' \n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # ตรวจสอบว่าคอลัมน์เนื้อหาหลักไม่ว่าง\n",
    "    if pd.isna(row[content_column]):\n",
    "        continue # ข้ามแถวที่ไม่มีเนื้อหาหลัก\n",
    "\n",
    "    page_content = str(row[content_column])\n",
    "    \n",
    "    # สร้าง metadata จากคอลัมน์อื่นๆ ทั้งหมด ยกเว้นคอลัมน์เนื้อหาหลัก\n",
    "    # ในกรณีนี้ 'คำตอบ' จะถูกเก็บใน metadata ของเอกสาร\n",
    "    metadata = row.drop(content_column).to_dict() \n",
    "\n",
    "    docs.append(Document(page_content=page_content, metadata=metadata))\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents from CSV.\")\n",
    "\n",
    "# --- 4. สร้าง Vector Store และบันทึกข้อมูลลง PostgreSQL ---\n",
    "print(\"Connecting to PGVector store and adding documents...\")\n",
    "# 'pre_delete_collection=True' จะลบ collection เก่าก่อนเพิ่มใหม่เสมอ\n",
    "vectorstore = PGVector.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=True # ตั้งค่าเป็น True ถ้าต้องการลบข้อมูลเก่าใน collection ก่อนเพิ่มใหม่\n",
    ")\n",
    "print(f\"Documents added to PostgreSQL in collection '{COLLECTION_NAME}'.\")\n",
    "\n",
    "# --- 5. ใช้ Vector Store เป็น Retriever และสร้าง RAG Chain ---\n",
    "# คุณสามารถปรับ k เพื่อดึงจำนวนเอกสารที่ต้องการมาใช้เป็นบริบทได้ (เช่น k=3, k=5)\n",
    "# ถ้าอยากให้ LLM ได้ context จาก 'คำถาม' และ 'คำตอบ' ให้ retriever ดึง metadata มาครบ\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1}) \n",
    "\n",
    "# สร้าง Prompt Template สำหรับ RAG Chain\n",
    "# เราจะส่งทั้ง 'คำถาม' (page_content) และ 'คำตอบ' (จาก metadata) ไปให้ LLM ใช้เป็นบริบท\n",
    "template = \"\"\"คุณคือผู้ช่วยที่ตอบคำถามอย่างเป็นมิตรและเป็นประโยชน์\n",
    "\n",
    "อ้างอิงจากข้อมูลบริบท (context) ที่ให้มาเท่านั้น หากไม่พบข้อมูลในบริบท ให้ระบุว่าไม่สามารถตอบคำถามจากข้อมูลที่มีได้\n",
    "\n",
    "Context (ข้อมูลที่เกี่ยวข้องจากฐานความรู้):\n",
    "{context}\n",
    "\n",
    "Question (คำถามจากผู้ใช้):\n",
    "{question}\n",
    "\n",
    "Answer (คำตอบ):\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# ---\n",
    "# ปรับส่วน context ใน rag_chain เพื่อส่งทั้ง 'คำถาม' (page_content) และ 'คำตอบ' (metadata['คำตอบ'])\n",
    "# ไปให้ LLM เพื่อให้มีบริบทที่ครบถ้วนยิ่งขึ้นในการสร้างคำตอบ\n",
    "# ---\n",
    "def format_docs_for_context(docs):\n",
    "    formatted_string = \"\"\n",
    "    for doc in docs:\n",
    "        # ดึง 'คำตอบ' จาก metadata\n",
    "        answer_content = doc.metadata.get('คำตอบ', 'ไม่พบข้อมูลคำตอบ')\n",
    "        # page_content คือ 'คำถาม' ที่เราใช้ในการ embed\n",
    "        question_content = doc.page_content \n",
    "        \n",
    "        formatted_string += f\"คำถาม: {question_content}\\n\"\n",
    "        formatted_string += f\"คำตอบ: {answer_content}\\n\\n\"\n",
    "    return formatted_string.strip() # ลบช่องว่างส่วนเกินที่ท้าย\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs_for_context, # ดึงเอกสารแล้วนำไปจัดรูปแบบเป็น context\n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- 6. ใช้ RAG Chain เพื่อรับคำตอบจาก AI ---\n",
    "query_text = \"วิธีเปลี่ยนรหัสผ่าน\" # คำถามที่คุณต้องการใช้ค้นหา\n",
    "print(f\"\\n--- Generating Answer for query: '{query_text}' ---\")\n",
    "final_answer = rag_chain.invoke(query_text)\n",
    "\n",
    "print(final_answer)\n",
    "\n",
    "print(\"\\nProcess completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
